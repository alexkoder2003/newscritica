import requests
from bs4 import BeautifulSoup
import re


def categories(cat):
    result = ''
    for i in cat:
        result += f'#{i} '
    return result


def parsing(url):
    page = requests.get(
        url
    )
    page.encoding = 'utf-8'
    base_url = url[:url.find('.site')+5]
    soup = BeautifulSoup(page.text, 'html.parser')



    title = soup.find('div', {
        'class': 'film'
    }).find('h1').text

    

    data = [title]
    if data[3]:
        text = f'''**ğŸ¬ [{data[0]} {data[1]}]({base_url+img})**
**ğŸ¿Ğ–Ğ°Ğ½Ñ€:** {categories(data[2])}
**â­Ğ ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ ĞšĞ¸Ğ½Ğ¾ĞŸĞ¾Ğ¸ÑĞº:** {data[3]}

ğŸ”Š{data[4]}

[ğŸ¬ Ğ¡Ğ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½]({url})
[ğŸ‘‰ Ğ’ÑĞµ Ñ„Ğ¸Ğ»ÑŒĞ¼Ñ‹](http://f1.ikino.site/filmy/) | [ğŸ‘‰ Ğ’ÑĞµ ÑĞµÑ€Ğ¸Ğ°Ğ»Ñ‹](http://f1.ikino.site/serialy/)'''
    else:
        text = f'''**ğŸ¬ [{data[0]} {data[1]}]({base_url+img})**
**ğŸ¿Ğ–Ğ°Ğ½Ñ€:** {categories(data[2])}

ğŸ”Š{data[4]}

[ğŸ¬ Ğ¡Ğ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½]({url})
[ğŸ‘‰ Ğ’ÑĞµ Ñ„Ğ¸Ğ»ÑŒĞ¼Ñ‹](http://f1.ikino.site/filmy/) | [ğŸ‘‰ Ğ’ÑĞµ ÑĞµÑ€Ğ¸Ğ°Ğ»Ñ‹](http://f1.ikino.site/serialy/)'''
    return text, url
